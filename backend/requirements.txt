fastapi>=0.104.1
uvicorn>=0.24.0
redis>=5.0.1
fastapi-cache2>=0.2.1
pydantic>=2.0.0
typing-extensions>=4.0.0
aioredis>=2.0.0
langchain==0.3.25
langchain-community>=0.3.23
llama-cpp-python>=0.1.50 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
chromadb==1.0.8
python-multipart==0.0.20